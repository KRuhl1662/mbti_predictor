{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "full_data = pd.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "# selecting random percentage of rows because of memory issues\n",
    "data = full_data.sample(frac = 0.2)\n",
    "data.columns = ['type', 'posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'1. Do you guys subscribe to holidays e.g. 4th...</td>\n",
       "      <td>107.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Very interesting test. Found some of the ques...</td>\n",
       "      <td>140.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...</td>\n",
       "      <td>105.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm quite sure that an ENTP can spend lots of...</td>\n",
       "      <td>123.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...</td>\n",
       "      <td>107.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I dislike being inconsistent. I also dislike ...</td>\n",
       "      <td>130.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Whatever. :p|||;)|||I can't ok? That's kind o...</td>\n",
       "      <td>115.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>':toast: likewise (though I already know lots ...</td>\n",
       "      <td>143.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Sensors r so dum lolol  da N label valid8 my ...</td>\n",
       "      <td>103.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Hogan-estp Austin-istp(on his podcast he's sta...</td>\n",
       "      <td>124.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len\n",
       "5145  INTJ  '1. Do you guys subscribe to holidays e.g. 4th...        107.84\n",
       "7098  ENFP  'Very interesting test. Found some of the ques...        140.62\n",
       "3358  INFP  'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...        105.18\n",
       "5518  ENTP  'I'm quite sure that an ENTP can spend lots of...        123.38\n",
       "1981  ISTJ  'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...        107.44\n",
       "...    ...                                                ...           ...\n",
       "6421  ENTP  'I dislike being inconsistent. I also dislike ...        130.82\n",
       "2208  INFJ  'Whatever. :p|||;)|||I can't ok? That's kind o...        115.96\n",
       "5412  INTJ  ':toast: likewise (though I already know lots ...        143.26\n",
       "6379  INFJ  'Sensors r so dum lolol  da N label valid8 my ...        103.62\n",
       "3409  INFP  Hogan-estp Austin-istp(on his podcast he's sta...        124.98\n",
       "\n",
       "[1735 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#calculating the average post length\n",
    "data['avg_post_len'] = data['posts'].apply(lambda x: (len(x) - x.count(\" \"))/50)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "      <th>tot_post_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'1. Do you guys subscribe to holidays e.g. 4th...</td>\n",
       "      <td>107.84</td>\n",
       "      <td>5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Very interesting test. Found some of the ques...</td>\n",
       "      <td>140.62</td>\n",
       "      <td>7031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...</td>\n",
       "      <td>105.18</td>\n",
       "      <td>5259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm quite sure that an ENTP can spend lots of...</td>\n",
       "      <td>123.38</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...</td>\n",
       "      <td>107.44</td>\n",
       "      <td>5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I dislike being inconsistent. I also dislike ...</td>\n",
       "      <td>130.82</td>\n",
       "      <td>6541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Whatever. :p|||;)|||I can't ok? That's kind o...</td>\n",
       "      <td>115.96</td>\n",
       "      <td>5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>':toast: likewise (though I already know lots ...</td>\n",
       "      <td>143.26</td>\n",
       "      <td>7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Sensors r so dum lolol  da N label valid8 my ...</td>\n",
       "      <td>103.62</td>\n",
       "      <td>5181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Hogan-estp Austin-istp(on his podcast he's sta...</td>\n",
       "      <td>124.98</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len  \\\n",
       "5145  INTJ  '1. Do you guys subscribe to holidays e.g. 4th...        107.84   \n",
       "7098  ENFP  'Very interesting test. Found some of the ques...        140.62   \n",
       "3358  INFP  'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...        105.18   \n",
       "5518  ENTP  'I'm quite sure that an ENTP can spend lots of...        123.38   \n",
       "1981  ISTJ  'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...        107.44   \n",
       "...    ...                                                ...           ...   \n",
       "6421  ENTP  'I dislike being inconsistent. I also dislike ...        130.82   \n",
       "2208  INFJ  'Whatever. :p|||;)|||I can't ok? That's kind o...        115.96   \n",
       "5412  INTJ  ':toast: likewise (though I already know lots ...        143.26   \n",
       "6379  INFJ  'Sensors r so dum lolol  da N label valid8 my ...        103.62   \n",
       "3409  INFP  Hogan-estp Austin-istp(on his podcast he's sta...        124.98   \n",
       "\n",
       "      tot_post_len  \n",
       "5145          5392  \n",
       "7098          7031  \n",
       "3358          5259  \n",
       "5518          6169  \n",
       "1981          5372  \n",
       "...            ...  \n",
       "6421          6541  \n",
       "2208          5798  \n",
       "5412          7163  \n",
       "6379          5181  \n",
       "3409          6249  \n",
       "\n",
       "[1735 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the total post length\n",
    "data['tot_post_len'] = data['posts'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the punctuation percentage\n",
    "# def punct_count(post):\n",
    "#     count = sum([1 for char in post if char in string.punctuation])\n",
    "#     return round(count/(len(post) - post.count(\" \")), 3)*100\n",
    "\n",
    "# data['punct_%'] = data['posts'].apply(lambda x: punct_count(x))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "      <th>tot_post_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'1. Do you guys subscribe to holidays e.g. 4th...</td>\n",
       "      <td>107.84</td>\n",
       "      <td>5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Very interesting test. Found some of the ques...</td>\n",
       "      <td>140.62</td>\n",
       "      <td>7031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...</td>\n",
       "      <td>105.18</td>\n",
       "      <td>5259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm quite sure that an ENTP can spend lots of...</td>\n",
       "      <td>123.38</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...</td>\n",
       "      <td>107.44</td>\n",
       "      <td>5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I dislike being inconsistent. I also dislike ...</td>\n",
       "      <td>130.82</td>\n",
       "      <td>6541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Whatever. :p|||;)|||I can't ok? That's kind o...</td>\n",
       "      <td>115.96</td>\n",
       "      <td>5798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>':toast: likewise (though I already know lots ...</td>\n",
       "      <td>143.26</td>\n",
       "      <td>7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Sensors r so dum lolol  da N label valid8 my ...</td>\n",
       "      <td>103.62</td>\n",
       "      <td>5181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>INFP</td>\n",
       "      <td>Hogan-estp Austin-istp(on his podcast he's sta...</td>\n",
       "      <td>124.98</td>\n",
       "      <td>6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len  \\\n",
       "0     INTJ  '1. Do you guys subscribe to holidays e.g. 4th...        107.84   \n",
       "1     ENFP  'Very interesting test. Found some of the ques...        140.62   \n",
       "2     INFP  'Aw thank you ☺️☺️ It's of the Shedd Aquarium ...        105.18   \n",
       "3     ENTP  'I'm quite sure that an ENTP can spend lots of...        123.38   \n",
       "4     ISTJ  'http://4.bp.blogspot.com/-9QjARWd5a84/T3OXHJJ...        107.44   \n",
       "...    ...                                                ...           ...   \n",
       "1730  ENTP  'I dislike being inconsistent. I also dislike ...        130.82   \n",
       "1731  INFJ  'Whatever. :p|||;)|||I can't ok? That's kind o...        115.96   \n",
       "1732  INTJ  ':toast: likewise (though I already know lots ...        143.26   \n",
       "1733  INFJ  'Sensors r so dum lolol  da N label valid8 my ...        103.62   \n",
       "1734  INFP  Hogan-estp Austin-istp(on his podcast he's sta...        124.98   \n",
       "\n",
       "      tot_post_len  \n",
       "0             5392  \n",
       "1             7031  \n",
       "2             5259  \n",
       "3             6169  \n",
       "4             5372  \n",
       "...            ...  \n",
       "1730          6541  \n",
       "1731          5798  \n",
       "1732          7163  \n",
       "1733          5181  \n",
       "1734          6249  \n",
       "\n",
       "[1735 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import nltk\n",
    "stopwords =nltk.corpus.stopwords.words('english')\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<1735x90246 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 720405 stored elements in Compressed Sparse Row format>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create function to clean the posts\n",
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return post\n",
    "\n",
    "#TF-IDF\n",
    "# tf_vectorize = TfidfVectorizer(analyzer=clean_posts)\n",
    "# X_tf = tf_vectorize.fit_transform(data['posts'])\n",
    "# X_tf_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_tf.toarray())], axis=1)\n",
    "\n",
    "# #Count Vectorizer\n",
    "count_vectorize = CountVectorizer(analyzer = clean_posts)\n",
    "X_count = count_vectorize.fit_transform(data['posts'])\n",
    "X_count_save = np.array(X_count)\n",
    "# X_count_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "X_count_feature = pd.DataFrame(X_count.toarray())\n",
    "X_count_feature.head()\n",
    "X_count_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90236</th>\n",
       "      <th>90237</th>\n",
       "      <th>90238</th>\n",
       "      <th>90239</th>\n",
       "      <th>90240</th>\n",
       "      <th>90241</th>\n",
       "      <th>90242</th>\n",
       "      <th>90243</th>\n",
       "      <th>90244</th>\n",
       "      <th>90245</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 90246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      \\\n",
       "0         0      0      0      0      0      0      0      0      0      0   \n",
       "1         0      0      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      0      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1730      0      0      0      0      0      0      0      0      0      0   \n",
       "1731      0      0      0      0      0      0      0      0      0      0   \n",
       "1732      0      0      0      0      0      0      0      0      0      0   \n",
       "1733      0      0      0      0      0      0      0      0      0      0   \n",
       "1734      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      ...  90236  90237  90238  90239  90240  90241  90242  90243  90244  \\\n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1730  ...      0      0      0      0      0      0      0      0      0   \n",
       "1731  ...      0      0      0      0      0      0      0      0      0   \n",
       "1732  ...      0      0      0      0      0      0      0      0      0   \n",
       "1733  ...      0      0      0      0      0      0      0      0      0   \n",
       "1734  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      90245  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "1730      0  \n",
       "1731      0  \n",
       "1732      0  \n",
       "1733      0  \n",
       "1734      0  \n",
       "\n",
       "[1735 rows x 90246 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1735x90246 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 720405 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9414b608df81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'post' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "param={'n_estimators':[400],'max_depth':[None]}\n",
    "\n",
    "gs=GridSearchCV(rf,param,cv=3,n_jobs=-1)\n",
    "gs_fit=gs.fit(X_count_feature,data['type'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = joblib.load(\"../count_vect_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"posts\":[\"I think I can I think I can I am not sure\"]})\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = pd.DataFrame()\n",
    "b = \"this can be your vectorizer thing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return post\n",
    "\n",
    "\n",
    "# #Count Vectorizer\n",
    "count_vectorize = CountVectorizer(analyzer = clean_posts)\n",
    "X_count = count_vectorize.fit_transform(test['posts'])\n",
    "X_count_feature = pd.DataFrame(X_count.toarray())\n",
    "\n",
    "X_count_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.predict(X_count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yo uname the file here\n",
    "with open('picklefile.pickle', 'wb') as f:\n",
    "    pickle.dump([a, b], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('picklefile.pickle', 'rb') as f:\n",
    "    loaded_vars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
