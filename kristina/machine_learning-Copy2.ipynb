{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lm = WordNetLemmatizer()\n",
    "stopwords =nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "full_data = pd.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "# selecting random percentage of rows because of memory issues\n",
    "data = full_data.sample(frac = 0.3)\n",
    "data.columns = ['type', 'posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'YES! I absolutely love this one, I've stumble...</td>\n",
       "      <td>152.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Insert random mainstream movie|||When I worke...</td>\n",
       "      <td>144.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'*breathes in* *breathes out*   ...That's nice...</td>\n",
       "      <td>152.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>102.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Disorder Rating Information      Paranoid: Mo...</td>\n",
       "      <td>138.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'That could create some kind of social movemen...</td>\n",
       "      <td>163.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Not gonna happen.  Genetically inferior is a ...</td>\n",
       "      <td>127.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Yeah, you can spot them indirectly. Generally...</td>\n",
       "      <td>106.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'I like to draw (appreciate art in general), l...</td>\n",
       "      <td>100.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...</td>\n",
       "      <td>126.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2602 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len\n",
       "5530  ENFJ  'YES! I absolutely love this one, I've stumble...        152.48\n",
       "2705  INFJ  'Insert random mainstream movie|||When I worke...        144.94\n",
       "7242  INFP  '*breathes in* *breathes out*   ...That's nice...        152.30\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...        102.50\n",
       "2945  INFJ  'Disorder Rating Information      Paranoid: Mo...        138.10\n",
       "...    ...                                                ...           ...\n",
       "7975  ENFP  'That could create some kind of social movemen...        163.30\n",
       "6989  ENFP  'Not gonna happen.  Genetically inferior is a ...        127.92\n",
       "625   INFJ  'Yeah, you can spot them indirectly. Generally...        106.22\n",
       "2829  ISFP  'I like to draw (appreciate art in general), l...        100.60\n",
       "6328  ESTP  'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...        126.18\n",
       "\n",
       "[2602 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#calculating the average post length\n",
    "data['avg_post_len'] = data['posts'].apply(lambda x: (len(x) - x.count(\" \"))/50)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "      <th>tot_post_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'YES! I absolutely love this one, I've stumble...</td>\n",
       "      <td>152.48</td>\n",
       "      <td>7624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Insert random mainstream movie|||When I worke...</td>\n",
       "      <td>144.94</td>\n",
       "      <td>7247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'*breathes in* *breathes out*   ...That's nice...</td>\n",
       "      <td>152.30</td>\n",
       "      <td>7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>102.50</td>\n",
       "      <td>5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Disorder Rating Information      Paranoid: Mo...</td>\n",
       "      <td>138.10</td>\n",
       "      <td>6905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'That could create some kind of social movemen...</td>\n",
       "      <td>163.30</td>\n",
       "      <td>8165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Not gonna happen.  Genetically inferior is a ...</td>\n",
       "      <td>127.92</td>\n",
       "      <td>6396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Yeah, you can spot them indirectly. Generally...</td>\n",
       "      <td>106.22</td>\n",
       "      <td>5311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'I like to draw (appreciate art in general), l...</td>\n",
       "      <td>100.60</td>\n",
       "      <td>5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...</td>\n",
       "      <td>126.18</td>\n",
       "      <td>6309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2602 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len  \\\n",
       "5530  ENFJ  'YES! I absolutely love this one, I've stumble...        152.48   \n",
       "2705  INFJ  'Insert random mainstream movie|||When I worke...        144.94   \n",
       "7242  INFP  '*breathes in* *breathes out*   ...That's nice...        152.30   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...        102.50   \n",
       "2945  INFJ  'Disorder Rating Information      Paranoid: Mo...        138.10   \n",
       "...    ...                                                ...           ...   \n",
       "7975  ENFP  'That could create some kind of social movemen...        163.30   \n",
       "6989  ENFP  'Not gonna happen.  Genetically inferior is a ...        127.92   \n",
       "625   INFJ  'Yeah, you can spot them indirectly. Generally...        106.22   \n",
       "2829  ISFP  'I like to draw (appreciate art in general), l...        100.60   \n",
       "6328  ESTP  'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...        126.18   \n",
       "\n",
       "      tot_post_len  \n",
       "5530          7624  \n",
       "2705          7247  \n",
       "7242          7615  \n",
       "4             5125  \n",
       "2945          6905  \n",
       "...            ...  \n",
       "7975          8165  \n",
       "6989          6396  \n",
       "625           5311  \n",
       "2829          5030  \n",
       "6328          6309  \n",
       "\n",
       "[2602 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the total post length\n",
    "data['tot_post_len'] = data['posts'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "      <th>tot_post_len</th>\n",
       "      <th>punct_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'YES! I absolutely love this one, I've stumble...</td>\n",
       "      <td>152.48</td>\n",
       "      <td>7624</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Insert random mainstream movie|||When I worke...</td>\n",
       "      <td>144.94</td>\n",
       "      <td>7247</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'*breathes in* *breathes out*   ...That's nice...</td>\n",
       "      <td>152.30</td>\n",
       "      <td>7615</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>102.50</td>\n",
       "      <td>5125</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Disorder Rating Information      Paranoid: Mo...</td>\n",
       "      <td>138.10</td>\n",
       "      <td>6905</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'That could create some kind of social movemen...</td>\n",
       "      <td>163.30</td>\n",
       "      <td>8165</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Not gonna happen.  Genetically inferior is a ...</td>\n",
       "      <td>127.92</td>\n",
       "      <td>6396</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Yeah, you can spot them indirectly. Generally...</td>\n",
       "      <td>106.22</td>\n",
       "      <td>5311</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'I like to draw (appreciate art in general), l...</td>\n",
       "      <td>100.60</td>\n",
       "      <td>5030</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...</td>\n",
       "      <td>126.18</td>\n",
       "      <td>6309</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2602 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len  \\\n",
       "5530  ENFJ  'YES! I absolutely love this one, I've stumble...        152.48   \n",
       "2705  INFJ  'Insert random mainstream movie|||When I worke...        144.94   \n",
       "7242  INFP  '*breathes in* *breathes out*   ...That's nice...        152.30   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...        102.50   \n",
       "2945  INFJ  'Disorder Rating Information      Paranoid: Mo...        138.10   \n",
       "...    ...                                                ...           ...   \n",
       "7975  ENFP  'That could create some kind of social movemen...        163.30   \n",
       "6989  ENFP  'Not gonna happen.  Genetically inferior is a ...        127.92   \n",
       "625   INFJ  'Yeah, you can spot them indirectly. Generally...        106.22   \n",
       "2829  ISFP  'I like to draw (appreciate art in general), l...        100.60   \n",
       "6328  ESTP  'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...        126.18   \n",
       "\n",
       "      tot_post_len  punct_%  \n",
       "5530          7624      7.4  \n",
       "2705          7247      6.7  \n",
       "7242          7615      8.5  \n",
       "4             5125      8.6  \n",
       "2945          6905      7.3  \n",
       "...            ...      ...  \n",
       "7975          8165      7.7  \n",
       "6989          6396      7.9  \n",
       "625           5311      9.8  \n",
       "2829          5030     13.3  \n",
       "6328          6309      9.0  \n",
       "\n",
       "[2602 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the punctuation percentage\n",
    "def punct_count(post):\n",
    "    count = sum([1 for char in post if char in string.punctuation])\n",
    "    return round(count/(len(post) - post.count(\" \")), 3)*100\n",
    "\n",
    "data['punct_%'] = data['posts'].apply(lambda x: punct_count(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>avg_post_len</th>\n",
       "      <th>tot_post_len</th>\n",
       "      <th>punct_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'YES! I absolutely love this one, I've stumble...</td>\n",
       "      <td>152.48</td>\n",
       "      <td>7624</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Insert random mainstream movie|||When I worke...</td>\n",
       "      <td>144.94</td>\n",
       "      <td>7247</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'*breathes in* *breathes out*   ...That's nice...</td>\n",
       "      <td>152.30</td>\n",
       "      <td>7615</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>102.50</td>\n",
       "      <td>5125</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Disorder Rating Information      Paranoid: Mo...</td>\n",
       "      <td>138.10</td>\n",
       "      <td>6905</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'That could create some kind of social movemen...</td>\n",
       "      <td>163.30</td>\n",
       "      <td>8165</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'Not gonna happen.  Genetically inferior is a ...</td>\n",
       "      <td>127.92</td>\n",
       "      <td>6396</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Yeah, you can spot them indirectly. Generally...</td>\n",
       "      <td>106.22</td>\n",
       "      <td>5311</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'I like to draw (appreciate art in general), l...</td>\n",
       "      <td>100.60</td>\n",
       "      <td>5030</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...</td>\n",
       "      <td>126.18</td>\n",
       "      <td>6309</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2602 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  avg_post_len  \\\n",
       "0     ENFJ  'YES! I absolutely love this one, I've stumble...        152.48   \n",
       "1     INFJ  'Insert random mainstream movie|||When I worke...        144.94   \n",
       "2     INFP  '*breathes in* *breathes out*   ...That's nice...        152.30   \n",
       "3     ENTJ  'You're fired.|||That's another silly misconce...        102.50   \n",
       "4     INFJ  'Disorder Rating Information      Paranoid: Mo...        138.10   \n",
       "...    ...                                                ...           ...   \n",
       "2597  ENFP  'That could create some kind of social movemen...        163.30   \n",
       "2598  ENFP  'Not gonna happen.  Genetically inferior is a ...        127.92   \n",
       "2599  INFJ  'Yeah, you can spot them indirectly. Generally...        106.22   \n",
       "2600  ISFP  'I like to draw (appreciate art in general), l...        100.60   \n",
       "2601  ESTP  'Imo:  ISFP/INFP ISFJ/INFJ ESTJ/ISTJ  Runnerup...        126.18   \n",
       "\n",
       "      tot_post_len  punct_%  \n",
       "0             7624      7.4  \n",
       "1             7247      6.7  \n",
       "2             7615      8.5  \n",
       "3             5125      8.6  \n",
       "4             6905      7.3  \n",
       "...            ...      ...  \n",
       "2597          8165      7.7  \n",
       "2598          6396      7.9  \n",
       "2599          5311      9.8  \n",
       "2600          5030     13.3  \n",
       "2601          6309      9.0  \n",
       "\n",
       "[2602 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create function to clean the posts with STEMMER\n",
    "# def clean_posts(post):\n",
    "#     post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "#     tokens = re.split('\\W+', post)\n",
    "#     post = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "#     return post\n",
    "\n",
    "# #TF-IDF\n",
    "# # tf_vectorize = TfidfVectorizer(analyzer=clean_posts)\n",
    "# # X_tf = tf_vectorize.fit_transform(data['posts'])\n",
    "# # X_tf_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_tf.toarray())], axis=1)\n",
    "\n",
    "# # #Count Vectorizer\n",
    "# count_vectorize = CountVectorizer(analyzer = clean_posts)\n",
    "# X_count = count_vectorize.fit_transform(data['posts'])\n",
    "# X_count_save = np.array(X_count)\n",
    "# # X_count_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "# X_count_feature = pd.DataFrame(X_count.toarray())\n",
    "# X_count_feature.head()\n",
    "# X_count_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data['posts'].values\n",
    "y = data['type'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(analyzer=<function clean_posts at 0x000001D51E3AFD08>)),\n",
       "                ('clf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('vect',CountVectorizer(analyzer = clean_posts)),\n",
    "        ('clf', RandomForestClassifier())\n",
    "        \n",
    "])\n",
    "\n",
    "pipe_parms = [{\n",
    "    'n_estimators' : [800],\n",
    "    'max_depth' : [None]\n",
    "}]\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs = GridSearchCV(pipe, param_grid= pipe_parms, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training data: ['ISTJ' 'INTJ' 'INTP' ... 'INFP' 'ENFJ' 'ISFJ']\n"
     ]
    }
   ],
   "source": [
    "# Predict training data\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "print(f\"Predictions on training data: {y_train_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test data: ['INFJ' 'INFP' 'INFP' 'INTJ' 'INTJ' 'INTP' 'INFJ' 'INFP' 'INFP' 'INFJ'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP'\n",
      " 'INFP' 'INTJ' 'INFP' 'INTP' 'INTJ' 'INFJ' 'INFP' 'INFP' 'INTJ' 'INFP'\n",
      " 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFP' 'INTJ' 'INTP' 'INTJ' 'INTJ' 'INFP'\n",
      " 'INFP' 'INTJ' 'INTP' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INFJ' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INTP'\n",
      " 'INTJ' 'INFP' 'INTP' 'INFP' 'INTP' 'INTP' 'INTP' 'INTP' 'INFP' 'INFP'\n",
      " 'INFP' 'INTP' 'INFP' 'INTJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INTP' 'ENTP'\n",
      " 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INTP'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INTP' 'INTP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP'\n",
      " 'INFJ' 'INFP' 'INTJ' 'INFP' 'INTJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP'\n",
      " 'INTP' 'INFP' 'INTJ' 'INFP' 'INFP' 'INTP' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INTP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INTJ' 'INFJ' 'INFP' 'INFP'\n",
      " 'INFP' 'INTP' 'INFJ' 'INFJ' 'INTJ' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INTP'\n",
      " 'INTP' 'INTJ' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INTP' 'INTP' 'INFP'\n",
      " 'INFJ' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP'\n",
      " 'INFP' 'INFJ' 'INTJ' 'INTP' 'INTP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INTP'\n",
      " 'INFP' 'INTP' 'INTJ' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INTP' 'INFP' 'INTJ'\n",
      " 'INFJ' 'INTP' 'INTP' 'INFP' 'INFP' 'INTP' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP'\n",
      " 'INFJ' 'INTJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ' 'INTP' 'INFP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFJ' 'INFP' 'INFP' 'INTP' 'INTP' 'INTP' 'INFP' 'INFP' 'INFJ'\n",
      " 'INFP' 'INFP' 'INTJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INTP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INTP' 'INFP' 'INTP' 'INFP' 'INFP'\n",
      " 'INFJ' 'INTJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP'\n",
      " 'INFJ' 'INTP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INFJ' 'INTP' 'INFP' 'INFJ' 'INFP' 'INFJ'\n",
      " 'INTJ' 'INFP' 'INTP' 'INFJ' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP'\n",
      " 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ' 'INTP' 'INTP'\n",
      " 'INFP' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP'\n",
      " 'INTP' 'INFJ' 'INTJ' 'INFJ' 'INFP' 'INTJ' 'INTP' 'INFP' 'INTP' 'INTJ'\n",
      " 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFJ' 'INFP' 'INTP'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INTP'\n",
      " 'INFJ' 'INFJ' 'INTJ' 'INFP' 'INFP' 'INFP' 'INFJ' 'INTP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INTJ' 'INFP' 'INFJ' 'INFP' 'INFP'\n",
      " 'INFP' 'INTJ' 'INFP' 'INTJ' 'INTP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INTP' 'INFP' 'INTP' 'INTP' 'INFJ'\n",
      " 'INTJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INTJ' 'INFP' 'INTP' 'INFP'\n",
      " 'INTP' 'INFP' 'INTJ' 'INTJ' 'INFP' 'INTJ' 'INFP' 'INTP' 'INFP' 'INFP'\n",
      " 'INTP' 'ENTP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INTP' 'INTJ' 'INFP'\n",
      " 'INFJ' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INTP' 'ENFP' 'INTP'\n",
      " 'INFP' 'INFP' 'INFJ' 'INFP' 'INTP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFJ'\n",
      " 'INTP' 'INTP' 'INFP' 'INFP' 'INFP' 'INTJ' 'INFJ' 'INTJ' 'INFP' 'INTJ'\n",
      " 'INFP' 'ENTP' 'INFP' 'ENTP' 'INTJ' 'INTP' 'INTP' 'INFP' 'INTP' 'INFP'\n",
      " 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFJ' 'INFJ'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INTP' 'INTP' 'INFP' 'INFJ'\n",
      " 'INTJ' 'INFP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ'\n",
      " 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ'\n",
      " 'INFP' 'INTP' 'INFP' 'INTJ' 'INFP' 'INFP' 'INFP' 'INFP' 'ENTP' 'INFJ'\n",
      " 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFJ'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INTJ' 'INFP' 'INTP' 'INFJ' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ'\n",
      " 'INFP' 'INFP' 'INFP' 'INFJ' 'INTJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP'\n",
      " 'INFJ' 'INFP' 'INTP' 'INFJ' 'INFJ' 'INTP' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
      " 'INFJ' 'INTP' 'INFP' 'INTP' 'INFP' 'INTP' 'INTP' 'INTP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFP' 'INTP'\n",
      " 'INFP' 'INFP' 'INFP' 'INTP' 'INFP' 'INFJ' 'INFJ' 'INTP' 'INFJ' 'INFJ'\n",
      " 'INFP' 'INTP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INFP'\n",
      " 'INFP' 'INFP' 'INFP' 'INFP' 'INFP' 'INTJ' 'INFP' 'INFP' 'INFP' 'INFP'\n",
      " 'INFP']\n"
     ]
    }
   ],
   "source": [
    "# Predict test data\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(f\"Predictions on test data: {y_test_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41781874039938555"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to clean the posts\n",
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [lm.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return post\n",
    "\n",
    "#TF-IDF\n",
    "# tf_vectorize = TfidfVectorizer(analyzer=clean_posts)\n",
    "# X_tf = tf_vectorize.fit_transform(data['posts'])\n",
    "# X_tf_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_tf.toarray())], axis=1)\n",
    "\n",
    "# #Count Vectorizer\n",
    "count_vectorize = CountVectorizer(analyzer = clean_posts)\n",
    "X_count = count_vectorize.fit_transform(data['posts'])\n",
    "X_count_save = np.array(X_count)\n",
    "# X_count_feature = pd.concat([data['avg_post_len'], data['punct_%'], pd.DataFrame(X_count.toarray())], axis=1)\n",
    "X_count_feature = pd.DataFrame(X_count.toarray())\n",
    "X_count_feature.head()\n",
    "X_count_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_count_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "param={'n_estimators':[800],'max_depth':[None]}\n",
    "\n",
    "gs=GridSearchCV(rf,param,cv=5,n_jobs=-1)\n",
    "gs_fit=gs.fit(X_count_feature,data['type'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_set, test_set = train_test_split(data, test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "\n",
    "X = ['I am a sentence', 'an example']\n",
    "Y = [1, 2]\n",
    "X_dev = ['another sentence']\n",
    "\n",
    "# classifier\n",
    "LinearSVC1 = LinearSVC(tol=1e-4,  C = 0.10000000000000001)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "       ('tfidf', TfidfVectorizer(ngram_range=(1, 3), max_features= 4000)), \n",
    "       ('custom_features', CustomFeatures())])),\n",
    "    ('clf', LinearSVC1),\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X, Y)\n",
    "y_pred = pipeline.predict(X_dev)\n",
    "\n",
    "# etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vect = 'vectorizer.sav'\n",
    "joblib.dump(X_count, filename_vect)\n",
    "\n",
    "filename_class = 'gs_rf_model.sav'\n",
    "joblib.dump(gs_fit, filename_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('picklefile.pickle', 'rb') as f:\n",
    "    loaded_vars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load('vectorizer.sav','rb')\n",
    "model = pickle.load(open('gs_rf_model.sav','rb'))\n",
    "pred = model.predict(vectorizer.transform(test['posts']))\n",
    "print (\"predicted class:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\"posts\":[\"I think I can I think I can I am not sure\"]})\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = joblib.load(\"../count_vect_model_w_lemm.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = pd.DataFrame()\n",
    "b = \"this can be your vectorizer thing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return post\n",
    "\n",
    "\n",
    "# #Count Vectorizer\n",
    "count_vectorize = CountVectorizer(analyzer = clean_posts)\n",
    "X_count = count_vectorize.fit_transform(test['posts'])\n",
    "X_count_feature = pd.DataFrame(X_count.toarray())\n",
    "\n",
    "X_count_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.predict(X_count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yo uname the file here\n",
    "with open('picklefile.pickle', 'wb') as f:\n",
    "    pickle.dump([a, b], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('picklefile.pickle', 'rb') as f:\n",
    "    loaded_vars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
