{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lm = WordNetLemmatizer()\n",
    "stopwords =nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "full_data = pd.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "# selecting random percentage of rows because of memory issues\n",
    "data = full_data.sample(frac = 0.1)\n",
    "data.columns = ['type', 'posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# #calculating the average post length\n",
    "# data['avg_post_len'] = data['posts'].apply(lambda x: (len(x) - x.count(\" \"))/50)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculating the total post length\n",
    "# data['tot_post_len'] = data['posts'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculating the punctuation percentage\n",
    "# def punct_count(post):\n",
    "#     count = sum([1 for char in post if char in string.punctuation])\n",
    "#     return round(count/(len(post) - post.count(\" \")), 3)*100\n",
    "\n",
    "# data['punct_%'] = data['posts'].apply(lambda x: punct_count(x))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I'm itching so hard for that 300 What's your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>Thank you! I am now quite sure that i am not x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'To be honest, I just stopped looking for rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'(Animated Music Video) Share your favorite or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Yes! I luckily managed to get home from uni b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'The naked women chase was the best, I think, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'It is definitely interesting to see the diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Yea I should have adressed I just meant in pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'a space whale - The only reason I worded it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=EOgfZHxTgts|||...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>868 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                                              posts\n",
       "0    INFP  'I'm itching so hard for that 300 What's your ...\n",
       "1    ISFJ  Thank you! I am now quite sure that i am not x...\n",
       "2    INFP  'To be honest, I just stopped looking for rela...\n",
       "3    INFJ  '(Animated Music Video) Share your favorite or...\n",
       "4    INTJ  'Yes! I luckily managed to get home from uni b...\n",
       "..    ...                                                ...\n",
       "863  INTJ  'The naked women chase was the best, I think, ...\n",
       "864  INFJ  'It is definitely interesting to see the diffe...\n",
       "865  INFJ  'Yea I should have adressed I just meant in pu...\n",
       "866  ENFP  'a space whale - The only reason I worded it l...\n",
       "867  ISTJ  'http://www.youtube.com/watch?v=EOgfZHxTgts|||...\n",
       "\n",
       "[868 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_posts(post):\n",
    "    post = \"\".join([word.lower()for word in post if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', post)\n",
    "    post = [lm.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return post\n",
    "\n",
    "#data['cleaned_posts'] = data['posts'].apply(lambda x: clean_posts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing piping\n",
    "data['posts']= data['posts'].str.replace('|',' ')\n",
    "\n",
    "# removing '\n",
    "data['posts']= data['posts'].str.replace(\"'\",'')\n",
    "\n",
    "# removing url's from posts\n",
    "data['posts'] = data['posts'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "\n",
    "# change case to lower\n",
    "data['posts'] = data['posts'].str.lower()\n",
    "\n",
    "\n",
    "#remove punctuation from posts\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punctuation = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return no_punctuation\n",
    "\n",
    "data['body_text_clean'] = data['posts'].apply(lambda x: remove_punctuation(x))\n",
    "\n",
    "# pulling types from type column\n",
    "mbti_types = data['type'].unique()\n",
    "\n",
    "# types to list instead of array\n",
    "mbti_list = mbti_types.tolist()\n",
    "\n",
    "# lowercasing types\n",
    "mbti_new = [x.lower() for x in mbti_list]\n",
    "\n",
    "# remove references to mbti type in body_text_clean column\n",
    "\n",
    "for item in mbti_new:\n",
    "    data['body_text_clean'] = data['body_text_clean'].str.replace(item , \"\")\n",
    "    \n",
    "# # apply word_tokenize to all records\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# data['tokenized'] = data['body_text_clean'].apply(word_tokenize)\n",
    "\n",
    "\n",
    "# # remove stopwords\n",
    "# def stopword_removal(text):\n",
    "#     stop_words = [item for item in text if item not in stopwords]\n",
    "#     return stop_words\n",
    "\n",
    "# data['stopwords'] = data['tokenized'].apply(lambda x: stopword_removal(x))\n",
    "\n",
    "def lemma_words(lemma):\n",
    "    lemmatize = [lm.lemmatize(word) for word in lemma]\n",
    "    return lemmatize\n",
    "\n",
    "data['lemmatized'] = data['body_text_clean'].apply(lambda x: lemma_words(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP</td>\n",
       "      <td>im itching so hard for that 300 whats your pro...</td>\n",
       "      <td>im itching so hard for that 300 whats your pro...</td>\n",
       "      <td>[i, m,  , i, t, c, h, i, n, g,  , s, o,  , h, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>thank you! i am now quite sure that i am not x...</td>\n",
       "      <td>thank you i am now quite sure that i am not xn...</td>\n",
       "      <td>[t, h, a, n, k,  , y, o, u,  , i,  , a, m,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>to be honest, i just stopped looking for relat...</td>\n",
       "      <td>to be honest i just stopped looking for relati...</td>\n",
       "      <td>[t, o,  , b, e,  , h, o, n, e, s, t,  , i,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>(animated music video) share your favorite or ...</td>\n",
       "      <td>animated music video share your favorite or ju...</td>\n",
       "      <td>[a, n, i, m, a, t, e, d,  , m, u, s, i, c,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>yes! i luckily managed to get home from uni be...</td>\n",
       "      <td>yes i luckily managed to get home from uni bef...</td>\n",
       "      <td>[y, e, s,  , i,  , l, u, c, k, i, l, y,  , m, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  \\\n",
       "0  INFP  im itching so hard for that 300 whats your pro...   \n",
       "1  ISFJ  thank you! i am now quite sure that i am not x...   \n",
       "2  INFP  to be honest, i just stopped looking for relat...   \n",
       "3  INFJ  (animated music video) share your favorite or ...   \n",
       "4  INTJ  yes! i luckily managed to get home from uni be...   \n",
       "\n",
       "                                     body_text_clean  \\\n",
       "0  im itching so hard for that 300 whats your pro...   \n",
       "1  thank you i am now quite sure that i am not xn...   \n",
       "2  to be honest i just stopped looking for relati...   \n",
       "3  animated music video share your favorite or ju...   \n",
       "4  yes i luckily managed to get home from uni bef...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [i, m,  , i, t, c, h, i, n, g,  , s, o,  , h, ...  \n",
       "1  [t, h, a, n, k,  , y, o, u,  , i,  , a, m,  , ...  \n",
       "2  [t, o,  , b, e,  , h, o, n, e, s, t,  , i,  , ...  \n",
       "3  [a, n, i, m, a, t, e, d,  , m, u, s, i, c,  , ...  \n",
       "4  [y, e, s,  , i,  , l, u, c, k, i, l, y,  , m, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data['posts'].values\n",
    "y = data['type'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('vect',CountVectorizer(analyzer = 'word')),\n",
    "        ('clf', RandomForestClassifier())\n",
    "        \n",
    "])\n",
    "\n",
    "pipe_parms = [{\n",
    "    'clf__n_estimators' : [600,800],\n",
    "    'clf__max_depth' : [None,200]\n",
    "}]\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training data\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "print(f\"Predictions on training data: {y_train_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict test data\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "print(f\"Predictions on test data: {y_test_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid= pipe_parms, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dumps(clean_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yo uname the file here\n",
    "with open('mbti_model.pickle', 'wb') as f:\n",
    "     pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # yo uname the file here\n",
    "# with open('mbti_model.pickle', 'wb') as f:\n",
    "#     pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('picklefile.pickle', 'rb') as f:\n",
    "#     loaded_vars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.predict(X_count_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
